# Hyperparameters for the Stable-Baselines3 PPO algorithm
total_timesteps: 1000000

# See SB3 documentation for details on each parameter
ppo_params:
  policy: 'MlpPolicy'
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  policy_kwargs:
    # Custom MLP architecture: two hidden layers of 256 neurons
    net_arch:
      - pi: [256, 256]
      - vf: [256, 256]